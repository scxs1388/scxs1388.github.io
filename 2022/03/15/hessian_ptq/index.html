<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/1AU4@TV694DZ7QW0MVVX7.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/1AU4@TV694DZ7QW0MVVX7.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"scxs1388.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":"default","style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="2022-03 人工智能前沿技术研讨课 个人课程作业留档">
<meta property="og:type" content="article">
<meta property="og:title" content="Hessian-based Post-Training Quantization">
<meta property="og:url" content="http://scxs1388.github.io/2022/03/15/hessian_ptq/index.html">
<meta property="og:site_name" content="I have tried my best to make this look like the title of a HYPERFLIP song, but it is still not long enough.">
<meta property="og:description" content="2022-03 人工智能前沿技术研讨课 个人课程作业留档">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/u5DvdWnXLeqVSzi.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/eDMna2HWUmEhJwI.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/W7ov398k4KwQMJz.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/YHxzlMbmFpyLZPD.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/UvwlgFQiH5Ks3Jf.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/Q5Z24FzTAafCePq.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/Bsa71WFxZHcowEC.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/k9NtK4ndgC6WxIj.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/XI6YSOckAlDw3q4.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/6YWBIScLUlN1KTX.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/Pp57F81SXcyOTvg.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/8OMswAEH7UWvGYB.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/opjyAJdLsQCmS7X.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/FSJeOwvZKW3kUgr.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/5ywcma3zeUfQjit.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/5ywcma3zeUfQjit.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/OrTRxlvtLEID4Ws.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/UvwfYtqh6uKpnHz.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/GuDA6avXFVfoUjW.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/hdjKBA2LsMN8IQp.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/dB3s2aZhxkcbUm7.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/JSqr9tYu4aCgT2G.png">
<meta property="og:image" content="https://s2.loli.net/2025/06/30/ahRES1oBC6mVUQM.png">
<meta property="article:published_time" content="2022-03-15T14:44:34.000Z">
<meta property="article:modified_time" content="2025-06-30T08:21:50.764Z">
<meta property="article:author" content="scxs1388">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Post-Training Quantization">
<meta property="article:tag" content="Hessian Matrix">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2025/06/30/u5DvdWnXLeqVSzi.png">

<link rel="canonical" href="http://scxs1388.github.io/2022/03/15/hessian_ptq/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hessian-based Post-Training Quantization | I have tried my best to make this look like the title of a HYPERFLIP song, but it is still not long enough.</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<script src="/live2d-widget/dist/autoload.js"></script>
<script>
/* parallax.js */
document.addEventListener('DOMContentLoaded', () => {
  const bg = document.getElementById('parallax-bg');
  const intensity = 16; // 控制移动幅度（值越大移动越明显）

  window.addEventListener('mousemove', (e) => {
    const x = (e.clientX / window.innerWidth - 0.5) * intensity;
    const y = (e.clientY / window.innerHeight - 0.5) * intensity;
    bg.style.transform = `translate(${-x}px, ${-y}px)`;
  });
});
</script>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="parallax-background" id="parallax-bg"></div>
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">I have tried my best to make this look like the title of a HYPERFLIP song, but it is still not long enough.</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">1</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">4</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/scxs1388" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://scxs1388.github.io/2022/03/15/hessian_ptq/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/37069157.jpg">
      <meta itemprop="name" content="scxs1388">
      <meta itemprop="description" content="Suffering from acute coke overdose">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="I have tried my best to make this look like the title of a HYPERFLIP song, but it is still not long enough.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hessian-based Post-Training Quantization
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-15 22:44:34" itemprop="dateCreated datePublished" datetime="2022-03-15T22:44:34+08:00">2022-03-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-30 16:21:50" itemprop="dateModified" datetime="2025-06-30T16:21:50+08:00">2025-06-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Reading/" itemprop="url" rel="index"><span itemprop="name">Paper Reading</span></a>
                </span>
            </span>

          
            <span id="/2022/03/15/hessian_ptq/" class="post-meta-item leancloud_visitors" data-flag-title="Hessian-based Post-Training Quantization" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/15/hessian_ptq/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/15/hessian_ptq/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>48 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>2022-03 人工智能前沿技术研讨课 个人课程作业留档</p>
<span id="more"></span>
<h1>引言</h1>
<h2 id="问题背景">问题背景</h2>
<p>2012 年，AlexNet 在 ILSVRC 比赛上大放异彩，人工智能也随之走入了以深度学习技术为主的新的发展时期。在之后的几年里，基于深度学习的算法或模型在任务上的性能改进都与模型的参数量成正相关。复杂的模型的计算时间和空间复杂度都很高，在资源受限的硬件上部署仍然具有很大挑战。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/u5DvdWnXLeqVSzi.png" alt="Figure. 1 深度神经网络参数量随年代增长变化曲线" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="神经网络量化的基本概念">神经网络量化的基本概念</h2>
<h3 id="量化">量化</h3>
<p>量化（Quantization）这一概念源自通信和信息学领域，是指一种从大（通常是连续）范围的输入值映射到（通常是离散）范围的输出值的方法。在数值计算问题中，量化问题指一组连续的实数值应该如何映射到一组取值固定的离散数值集合上，从而能够最大限度地减少数值表示所需的位数并最大限度地提高计算的精度。近年来，由于基于深度学习的神经网络模型的复杂度不断提高，对神经网络的量化问题的研究逐渐成为人工智能技术应用和神经网络计算优化的重要子领域。<br>
针对深度神经网络的量化一般有两个目的：网络压缩和推理加速。网络压缩指通过降低模型参数（包括权重和激活值）的数值表示所需的位数，达到降低内存容量和带宽的效果，例如将一个参数全部是 32 位浮点数的神经网络的权重和激活值全部量化到 8 位整型数值，其内存占用和带宽理论上均可减少至原来的四分之一。而实现推理加速则是利用量化从高精度映射到低精度数值表示的特性，进行进一步的低精度（如整型）的计算优化，减少模型计算推理的时间，例如对 8 位整型数的乘法运算进行优化，可以理论上实现相比 32 位浮点数的乘法运算的速度快 16 倍的加速效果。<br>
量化时的浮点数离散化操作会造成精度损失，因此在量化操作之后得到的值会与原真实值存在差异，这个差异叫作量化误差（Quantization Error）。直观上来说，将全精度的数值映射为低精度的数值会不可避免地导致信息丢失，这个过程中会对神经网络模型引入量化误差，导致模型预测精度的下降。但是实际上许多量化神经网络的表现与原始神经网络相差无几。关于量化误差与模型预测精度的相关性，目前尚未出现严谨的理论证明。一个可能的解释是：当前多数神经网络模型都存在严重的参数冗余，模型参数的自由度较高，因此对于参数的量化具有较高的鲁棒性。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/eDMna2HWUmEhJwI.png" alt="Figure. 2 神经网络量化的模型压缩和加速" :="" width="60%" loading="lazy" style="margin-bottom: 30px;"></p>
<h3 id="量化的数学表示">量化的数学表示</h3>
<p>量化可以表示为一个单射函数 $Q$，该函数将输入的浮点数值集合 $X$ 映射到离散的数值集合 $Y$。函数 $Q$ 在过去的研究中有多种实现方式，其中使用得最为广泛的是对称仿射量化（Symmetric Affine Quantization），或者叫作对称线性量化（Symmetric Linear Quantization）。对称线性量化的一般形式如下：<br>
$$<br>
\begin{align*}<br>
&amp;Q(\mathbf{x}) = \text{clip}\left(\text{round}\left(\frac{\mathbf{x}}{s}\right)\right)\\<br>
&amp;\hat{\mathbf{x}} = s \cdot Q(\mathbf{x})<br>
\end{align*}<br>
$$</p>
<p>对于某一粒度规模（Layer-wise 或者 Channel-wise）的参数，对称线性量化使用一个缩放系数 $s$ 来调整原始集合的数值范围到固定的数值范围，然后经过舍入 $\text{round}$ 和截断 $\text{clip}$ 的方式实现取值的离散化，最后重新使用缩放系数 $s$ 来恢复到原始集合的数值范围。使用对称线性量化的好处是：在求解量化问题时需要优化的参数只有量化的缩放系数 $s$，并且量化神经网络在实际进行乘法运算时，可以提取出计算过程中不同的缩放系数 $s$，先进行低精度的整数乘法，然后统一进行缩放运算，这样可以简化运算，实现计算加速效果，如 Figure. 3 所示。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/W7ov398k4KwQMJz.png" alt="Figure. 3 伪量化和真实量化计算示意图" :="" width="90%" loading="lazy" style="margin-bottom: 30px;"></p>
<h3 id="后训练量化和量化感知训练">后训练量化和量化感知训练</h3>
<p>后训练量化（Post-Training Quantization, PTQ），又称离线量化，指的是将一个预训练的神经网络模型通过参数优化等方法获得一个量化的神经网络模型，一般不会涉及网络的再训练过程。离线量化方法可以快速获取一个量化模型，可以节省训练所需的计算资源，并且更适合快速迭代的应用场景。针对激活值的离线量化需要使用一个小规模的数据集作为校准集（Calibration Dataset），通过对校准集进行推理来统计激活值的数值范围，从而实现对激活的量化优化。<br>
量化感知训练（Quantization-Aware Training，QAT），又称在线量化。与离线量化不同，在线量化将量化映射函数事先插入到模型的计算图中需要被量化的参数的位置，并对模型使用完整的训练集进行训练。再训练过程不仅会优化原始任务的损失，同时也会优化量化误差带来的量化损失。使用量化感知训练得到的量化模型通常比后训练量化得到的模型的预测准确度更高，但需要消耗大量的计算资源，并且超参数的设定也会对量化模型的收敛产生影响。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/YHxzlMbmFpyLZPD.png" alt="Figure. 4 后训练量化与量化感知训练在数据和训练两个维度的区别" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="Hessian-矩阵">Hessian 矩阵</h2>
<p>海森矩阵（Hessian Matrix），或称作黑塞矩阵、海瑟矩阵等，是由多元函数的二阶偏导数构成的方阵。对于复杂的优化问题，其目标函数往往较为复杂。为了使问题简化，可以将目标函数在某点的邻域进行二阶泰勒展开（Taylor Expansion）来逼近原函数，其中的二阶项就包含 Hessian 矩阵。<br>
例如，对于一个多元函数 $\mathcal{F}(\mathbf{x})$，其在点 $\mathbf{x}_0$ 处的二阶泰勒展开可以表示为：<br>
$$<br>
\begin{align*}<br>
\mathcal{F}(\mathbf{x}) \approx \mathcal{F}(\mathbf{x}_0) + \nabla \mathcal{F}(\mathbf{x}_0)^{T} \cdot \Delta \mathbf{x} + \frac{1}{2} \Delta \mathbf{x}^{T} \cdot \nabla^{2} \mathcal{F}(\mathbf{x}_0) \cdot \Delta \mathbf{x},<br>
\end{align*}<br>
$$</p>
<p>其中的二阶偏导数矩阵 $\mathbf{H}^{(\mathbf{x})} = \nabla^{2} \mathcal{F}(\mathbf{x}_0)$ 就是 $\mathcal{F}$ 在点 $\mathbf{x}_0$ 处的 Hessian 矩阵，$\Delta \mathbf{x} = \mathbf{x} - \mathbf{x}_0$ 是 $\mathbf{x}$ 相对于 $\mathbf{x}_0$ 的偏移量。<br>
在深度神经网络的优化问题中，Hessian 矩阵可以用来描述损失函数在参数空间中的 Loss landscape。已有的工作例如 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.07145">PyHessian</a><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> 通过近似计算 Hessian 矩阵的特征向量（Eigenvalue）、迹（Trace），可以获得关于损失函数的二阶信息，从而更好地对不同模型和优化器的性能进行比较和分析。<br>
本次介绍的三篇论文 AdaRound<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>、BRECQ<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>、QDrop<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> 均使用了 Hessian 矩阵来优化量化神经网络模型的性能。</p>
<h1>AdaRound</h1>
<blockquote>
<ul>
<li>Title: <strong>Up or Down? Adaptive Rounding for Post Training Quantization</strong></li>
<li>Venue: <em><strong>ICML 2020</strong></em></li>
<li>Author(s): <em>Markus Nagel, Rana Ali Amjad, Mart van Baalen, Christos Louizos, Tijmen Blankevoort</em></li>
<li>Institution(s): <em>Qualcomm AI Research</em></li>
<li>Link: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.10518">arxiv:2006.10518</a></li>
</ul>
</blockquote>
<h2 id="前言">前言</h2>
<p>在进行神经网络的后训练量化时，预训练模型的权重参数 $\mathbf{w}$ 和对应的量化缩放系数 $\mathbf{s}$ 已经确定，则对于量化误差 $\Delta \mathbf{w}$ 也已确定。假设预训练模型在原始任务上的全局损失为 $\mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w})$，其中 $\mathbf{x}$ 为输入样本，$\mathbf{y}$ 为预测真值，$\mathbf{w}$ 为模型参数。将对模型参数 $\mathbf{w}$ 的量化看作为对 $\mathbf{w}$ 的一个扰动，即 $Q(\mathbf{w})=\mathbf{w}+\Delta \mathbf{w}$。那么，该预训练模型的量化对全局损失的期望及其二阶泰勒展开的近似可以表示为：<br>
$$<br>
\begin{align*}<br>
&amp; \mathbb{E}[\mathcal{L}(\mathbf{x}, \mathbf{y}, Q(\mathbf{w}))]\\<br>
\overset{(a)}{\approx} &amp; \mathbb{E}[\Delta\mathbf{w}^{T} \cdot \nabla \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w}) + \frac{1}{2} \Delta\mathbf{w}^{T} \cdot \nabla^{2} \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w}) \cdot \Delta\mathbf{w}]\\<br>
= &amp; \Delta \mathbf{w}^{T} \cdot \mathbf{g}^{(\mathbf{w})} + \frac{1}{2} \Delta \mathbf{w}^{T} \cdot \mathbf{H}^{(\mathbf{w})} \cdot \Delta \mathbf{w},<br>
\end{align*}<br>
$$</p>
<p>其中 $\mathbf{g}^{(\mathbf{w})}$ 为原始任务损失 $\mathcal{L}$ 对 $\mathbf{w}$ 的一阶偏导数向量，$\mathbf{H}^{(\mathbf{w})}$ 为 Hessian 矩阵：<br>
$$<br>
\begin{align*}<br>
\mathbf{g}^{(\mathbf{w})} &amp; = \mathbb{E} \left[ \nabla_{\mathbf{w}} \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w}) \right]\\<br>
\mathbf{H}^{(\mathbf{w})} &amp; = \mathbb{E} \left[ \nabla_{\mathbf{w}}^{2} \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w})\right].<br>
\end{align*}<br>
$$</p>
<p>由于使用的是已训练至收敛的预训练模型，可以假设原任务损失对模型参数 $\mathbf{w}$ 的一阶偏导数为 $0$，即泰勒展开一阶项为 $0$。常数项也相互抵消。因此，量化对全局损失的期望可以近似用泰勒展开的二阶项来表示：<br>
$$<br>
\mathbb{E}[\mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w} + \Delta \mathbf{w}) - \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w})] = \frac{1}{2} \Delta \mathbf{w}^{T} \cdot \mathbf{H}^{(\mathbf{w})} \cdot \Delta \mathbf{w}.<br>
$$</p>
<p>这样，针对网络模型参数的量化问题就转化为了对包含 Hessian 矩阵的二次型的优化问题。为了更好地理解这个问题，不妨设 $\mathbf{w}$ 包含两个参数 $\mathbf{w}^{T}=[w_{1}, w_{2}]$，对应的量化误差为 $\Delta \mathbf{w}^{T}=[\Delta w_{1}, \Delta w_{2}]$，若对应的 Hessian 矩阵为：<br>
$$<br>
\mathbf{H}^{(\mathbf{w})} =<br>
\begin{bmatrix}<br>
1 &amp; 0.5 \\<br>
0.5 &amp; 1<br>
\end{bmatrix},<br>
$$</p>
<p>则量化误差对全局损失的影响可以表示为：<br>
$$<br>
\Delta \mathbf{w}^{T} \cdot \mathbf{H}^{(\mathbf{w})} \cdot \Delta \mathbf{w} = \Delta w_{1}^{2} + \Delta w_{2}^{2} + \Delta w_{1} \Delta w_{2},<br>
$$</p>
<p>其中位于 Hessian 矩阵对角线上的二次型项恒为非负，其必然会导致量化误差对全局损失的增加。而 Hessian 矩阵的非对角线项可正可负，会导致量化误差之间的交互作用。若扰动方向相反，则可以使得模型全局损失减小。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/UvwlgFQiH5Ks3Jf.png" alt="Figure. 5 AdaRound 自适应舍入方法主要示意图" :="" width="50%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>AdaRound 提出了一个全新的模型量化算法的优化视角：传统的就近舍入（Round to Nearest）方法会将量化误差 $\Delta \mathbf{w}$ 的每个分量 $\Delta w_{i}$ 都舍入到最接近的整数值 $Q(\Delta w_{i})$，这并不一定是最优解。如 Figure. 5 所示，通过优化量化误差 $\Delta \mathbf{w}$ 的每个分量的舍入方向（Up or Down），可能会使得量化误差对全局损失的影响更小。</p>
<h2 id="方法">方法</h2>
<h3 id="从全局损失到局部损失">从全局损失到局部损失</h3>
<p>AdaRound 将量化误差对全局损失的影响的期望作为优化目标函数：<br>
$$<br>
\begin{align*}<br>
\underset{\Delta \mathbf{w}}{\arg\min} \space \mathbb{E}[\mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w} + \Delta \mathbf{w}) - \mathcal{L}(\mathbf{x}, \mathbf{y}, \mathbf{w})]<br>
\end{align*}<br>
$$</p>
<p>该目标函数可以转化为包含 Hessian 矩阵的二次型形式：<br>
$$<br>
\begin{align*}<br>
\underset{\Delta \mathbf{w} ^{(\ell)}}{\arg\min} \space<br>
\mathbb{E}[\Delta {\mathbf{w} ^{(\ell)}} ^{T} \cdot \mathbf{H} ^{(\mathbf{w})} \cdot \Delta \mathbf{w} ^{(\ell)}]<br>
\end{align*}<br>
$$</p>
<p>对于常见粒度的参数量化而言，其 Hessian 矩阵的规模很大，很难在有限时间内进行计算和求解。AdaRound 对该问题进行了简化。首先，AdaRound 将参数粒度限制在了 Layer-wise 层级，即每次优化只考虑一个参数层的所有参数。对于模型的每一层 $\ell$ 中的权重参数 $\mathbf{W}^{(\ell)}$，全局损失 $\mathcal{L}$ 对其的二阶偏导数可以表示为：<br>
$$<br>
\begin{align*}<br>
\frac{\partial^{2} \mathcal{L}}{\partial \mathbf{W} _{i,j} ^{(\ell)} \partial \mathbf{W} _{m,o} ^{(\ell)}} &amp; = \frac{\partial}{\partial \mathbf{W} _{m,o} ^{(\ell)}} \left[ \frac{\partial\mathcal{L}}{\partial \mathbf{z} _{i} ^{(\ell)}} \cdot \mathbf{x} _{j} ^{(\ell-1)} \right] \\<br>
&amp; = \frac{\partial ^{2} \mathcal{L}}{\partial \mathbf{z} _{i} ^{(\ell)} \partial \mathbf{z} _{m} ^{(\ell)}} \cdot \mathbf{x} _{j} ^{(\ell-1)} \cdot \mathbf{x} _{o}^{(\ell-1)},<br>
\end{align*}<br>
$$</p>
<p>那么，损失函数对该层参数的 Hessian 矩阵可以表示为：<br>
$$<br>
\mathbf{H} ^{(\mathbf{W} ^{(\ell)})} = \mathbb{E} \left[ \mathbf{x} ^{(\ell-1)} \cdot {\mathbf{x} ^{(\ell-1)}} ^{T} \otimes \nabla _{\mathbf{z} ^{(\ell)}} ^{2} \mathcal{L} \right],<br>
$$</p>
<p>其中 $\mathbf{x}^{(\ell-1)}$ 为上一层的输出激活值，$\mathbf{z}^{(\ell)}$ 为该层的预激活值，$\otimes$ 表示 Kronecker 积。AdaRound 分别基于两个不同的假设对该 Hessian 矩阵进行了简化。</p>
<p><strong>假设一</strong>：Hessian 矩阵 $\mathbf{H} ^{(\mathbf{W} ^{(\ell)})}$ 为对角矩阵，即本层网络的神经元输出相互独立。在此假设下，Hessian 矩阵可以简化为：<br>
$$<br>
\mathbf{H} ^{(\mathbf{W} ^{(\ell)})} = \mathbb{E} \left[\mathbf{x} ^{(\ell-1)}\cdot{\mathbf{x} ^{(\ell-1)}} ^{T}\otimes\text{diag}(\nabla _{\mathbf{z} ^{(\ell)}} ^{2}\mathcal{L} _{i,i}) \right].<br>
$$</p>
<p><strong>假设二</strong>：损失函数 $\mathcal{L}$ 对 $\mathbf{z} ^{(\ell)}$ 的二阶偏导数是常数，即与输入激活值 $\mathbf{x} ^{(\ell - 1)}$ 无关。因此 $\nabla _{\mathbf{z} ^{(\ell)}} ^{2} \mathcal{L}$ 是一个常数矩阵。这样目标函数就省略了加权项，最终简化为对当前层预激活输出的均方误差（Mean Squared Error, MSE）的形式：<br>
$$<br>
\begin{align*}<br>
&amp; \underset{\Delta \mathbf{W} _{k,:} ^{(\ell)}}{\arg\min} &amp;&amp; \mathbb{E} \left[ \nabla _{\mathbf{z} ^{(\ell)}} ^{2} \mathcal{L} _{k,k} \cdot \Delta \mathbf{W} _{k,:} ^{(\ell)} \mathbf{x} ^{(\ell-1)} {\mathbf{x} ^{(\ell-1)}} ^{T} {\Delta \mathbf{W} _{k,:} ^{(\ell)}} ^{T} \right]\\<br>
=\space &amp; \underset{\Delta \mathbf{W} _{k,:} ^{(\ell)}}{\arg\min} &amp;&amp; \Delta \mathbf{W} _{k,:} ^{(\ell)} \mathbb{E} \left[ \mathbf{x} ^{(\ell-1)}{\mathbf{x} ^{(\ell-1)}} ^{T} \right] {\Delta \mathbf{W} _{k,:} ^{(\ell)}} ^{T} \\<br>
=\space &amp; \underset{\Delta \mathbf{W} _{k,:} ^{(\ell)}}{\arg\min} &amp;&amp; \mathbb{E} \left[ \left( \Delta \mathbf{W} _{k,:} ^{(\ell)} \mathbf{x} ^{(\ell-1)} \right) ^{2} \right]<br>
\end{align*}<br>
$$</p>
<p>通过以上对问题的简化，原始的全局损失转化为了每一层预激活输出 MSE 的局部损失。这样只需要进行逐层进行优化局部损失，即可完成对量化误差的优化。</p>
<h3 id="AdaRound">AdaRound</h3>
<p>为了对舍入方向进行优化，AdaRound 设计了一种对上述局部损失的优化方法。AdaRound 的目标函数为当前层预激活 MSE 加入了一个正则化项。正则化项的参数 $\mathbf{V}$ 是与参数 $\mathbf{W}$ 同维度的可学习参数，用来控制量化误差的舍入方向。AdaRound 的目标函数可以表示为：<br>
$$<br>
\underset{\Delta \mathbf{W}^{(\ell)}}{\arg\min} \space | \mathbf{W}\mathbf{x} - \widetilde{\mathbf{W}}\mathbf{x} | _{F} ^{2} + \lambda f _{reg}(\mathbf{V}),<br>
$$</p>
<p>其中 $\widetilde{\mathbf{W}}$ 是经过量化的权重参数：<br>
$$<br>
\widetilde{\mathbf{W}} = s \cdot \text{clip} \left( \left\lfloor \frac{\mathbf{W}}{s} \right\rfloor + h(\mathbf{V}),n,p \right).<br>
$$</p>
<p>与常规的对称线性量化函数不同，AdaRound 的量化函数将就近舍入改为向下取整后加上一个整流函数 $h$：<br>
$$<br>
h(\mathbf{V} _{i,j}) = \text{clip} \left( \sigma(\mathbf{V} _{i,j})(\zeta - \gamma) + \gamma, 0, 1 \right),<br>
$$</p>
<p>整流函数 $h$ 的输入为 $\mathbf{V}$，输出为普通 Sigmoid 函数 $\sigma$ 经过范围缩放后再进行截断至范围 $[0,1]$ 之间的结果，表示当前参数的自适应舍入方向。这样设计的目的是为了避免 Sigmoid 函数在趋近 $0$ 或 $1$ 时的梯度消失问题。其中，缩放系数 $\zeta$ 和 $\gamma$ 分别设定为 $\zeta=1.1$ 和 $\gamma=-0.1$。<br>
$$<br>
f _{reg} (\mathbf{V}) = \sum _{i,j} 1 - | 2h(\mathbf{V} _{i,j}) - 1 | ^{\beta},<br>
$$</p>
<p>AdaRound 目标函数的正则项 $f _{reg}$ 使用退火温度参数 $\beta$ 来指导可学习参数 $\mathbf{V}$ 的收敛。温度参数 $\beta$ 的值初始化为较大的数值，在初始阶段加大惩罚力度帮助 $\mathbf{V}$ 收敛。之后在优化过程中逐渐减小，进一步优化预激活 MSE。<br>
考虑到神经网络中量化误差会逐层累加，上述优化过程也是逐层进行。为了避免累加的量化误差对最终模型精度的影响，在逐层优化的过程中，当前被量化层的输入是之前所有层经过量化后得到的输出。除此之外，激活函数对量化的影响也需要被考虑到优化范围内。这样就得到了 AdaRound 最终的优化目标函数。<br>
$$<br>
\underset{\mathbf{V}}{\arg\min} \space \left| f _{a}(\mathbf{W} \mathbf{x}) - f _{a}(\widetilde{\mathbf{W}} \hat{\mathbf{x}})  \right| _{F} ^{2} + \lambda f _{reg} (\mathbf{V}),<br>
$$</p>
<h2 id="实验">实验</h2>
<h3 id="消融实验">消融实验</h3>
<p>本文从以下五个方面展开了消融实验，验证本文所提出方法的有效性。<br>
<strong>从全局损失到局部损失目标函数的选择</strong>。本文对比了原始的就近舍入量化、Hessian 矩阵二次型、预激活 MSE 以及 AdaRound 目标函数的模型参数重建量化效果，结果表明，使用 AdaRound 的目标函数进行优化的量化效果最优。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/Q5Z24FzTAafCePq.png" alt="Table. 1 不同局部损失目标函数的对比实验" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<p><strong>AdaRound 整流函数 $h$ 的选择</strong>。本文对比了使用退火参数的 Sigmoid 函数、普通 Sigmoid 函数加正则项函数以及整流函数 $h$ 加正则化项三种情况，结果表明，使用整流函数 $h$ 加正则化项能够在网络整体的量化上达到更好的效果。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/Bsa71WFxZHcowEC.png" alt="Table. 2 不同整流函数 $h$ 的对比实验" :="" width="40%&quot;" loading="lazy" style="margin-bottom: 30px;"></p>
<p><strong>使用 STE 进行优化</strong>。本文对比了使用辅助变量进行优化重建的方法以及使用直通估计器（Straight Through Estimator，STE）进行量化感知训练的方法。结果表明，使用重建的方法要比使用 STE 的 QAT 方法效果要更好一些，原因是 STE 可能会导致量化前后的参数反向传播时梯度不匹配（Gradient Mismatch）问题。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/k9NtK4ndgC6WxIj.png" alt="Table. 3 是否使用 STE 进行微调的对比实验" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<p><strong>优化参数缩放系数的指标</strong>。AdaRound 仍然沿用原始的对称线性量化函数，因此在进行重建前需要提前优化确定参数的缩放系数 $s$，一般采用网格搜索的方法来穷举某一目标函数的值，取某种指标的最优值点来确定缩放系数。本文对比了最大最小值差、权重参数 MSE 和激活 MSE 三种指标函数，结果表明，使用权重 MSE 或激活 MSE 对 AdaRound 初始化都能获得较优的量化效果。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/XI6YSOckAlDw3q4.png" alt="Table. 4 使用不同优化参数缩放系数指标初始化的对比实验" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<p><strong>校准集样本量大小</strong>。本文对校准集的大小对量化的影响进行了探究。结果表明，校准集样本数量越大，量化导致的模型预测损失越低。另外，AdaRound 对校准集的采样来源具有较高的鲁棒性，使用不同任务的数据集作为校准集只会有很微小的精度下降。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/6YWBIScLUlN1KTX.png" alt="Figure. 6 不同校准集样本量大小情况下的对比实验" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<h3 id="对比实验">对比实验</h3>
<p>AdaRound 主要对比了 2020 年以前在 ImageNet 图像分类任务上对经典卷积神经网络模型的各种量化方法。结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/Pp57F81SXcyOTvg.png" alt="Table. 5 AdaRound 在 ImageNet 图像分类任务的各模型上的对比实验结果" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="总结">总结</h2>
<p>本文提出了 AdaRound，一种对舍入进行优化的后训练量化方法。同样是对网络的权重参数做优化，不同于过去使用深度学习常用的基于全局损失的梯度下降的优化方式，这种方法采用经过特殊设计的优化目标函数来对一部分可学习参数做微调。这种优化方法也被称为基于重建（Reconstruction）的量化方法。TSQ<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>、AdaQuant<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>、Bit Split<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> 等针对模型量化的研究也使用了类似的基于重建的量化方法。优化相比传统的线性量化方法，AdaRound 在最终量化模型的推理精度上有着明显的提升。<br>
Qualcomm AI 研究院在将 AdaRound 方法用在了其全新推出的深度学习模型部署框架 AIMET<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup> 中作为核心后训练量化算法，推进了深度模型的轻量化发展与实际场景的应用。</p>
<h1>BRECQ</h1>
<blockquote>
<ul>
<li>Title: <strong>BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction</strong></li>
<li>Venue: <em><strong>ICLR 2021</strong></em></li>
<li>Author(s): Yuhang Li, Ruihao Gong, Xu Tan, Yang Yang, Peng Hu, Qi Zhang, Fengwei Yu, Wei Wang, Shi Gu</li>
<li>Institution(s): University of Electronic Science and Technology of China, SenseTime Research</li>
<li>Link: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.05426v2">arxiv:2102.05426</a></li>
</ul>
</blockquote>
<h2 id="前言-2">前言</h2>
<p>AdaRound 为后训练量化算法指明了一个很好的方向：利用包含 Hessian 矩阵的二次型来近似量化的全局损失函数。然而，AdaRound 优化方法仍然存在一些局限性：AdaRound 采用层级的量化粒度，忽略了不同层参数之间的相关性，这样会导致在极低比特量化下模型推理精度大幅下降；另外，AdaRound 在将全局损失转化为局部损失时基于两个强假设，忽略了同一层间不同参数的部分相关性和的相关性，这样实际会损失过多有价值的信息。为了摆脱这些局限性，以获得更好的量化效果，本文在 AdaRound 的基础上提出了新的基于块级重建（Block-wise Reconstruction）的优化方法 BRECQ，对上面提到的问题进行了针对性的改进。</p>
<h2 id="方法-2">方法</h2>
<h3 id="不同层间参数的相关性">不同层间参数的相关性</h3>
<p>神经网络的后训练量化一般选择层级的量化粒度，即网络中的每一个参数化层分别对应一个量化映射，这直观上与深度神经网络层级堆叠的设计结构相吻合，但是却忽略了层级之间的参数的相关性。层级量化本质上是对量化这一全局优化问题的简化，显然，神经网络作为一个优化的整体，层级之间参数的相关性必然会对量化效果产生影响。此时仍可以借助 Hessian 矩阵来探究层级之间参数的相关性。<br>
记神经网络的预激活 $\mathbf{z} ^{(n)} = f(\theta)$，任务损失函数为 $L(f(\theta))$，其中 $\theta$ 为网络的参数。则损失函数对网络中任意参数的二阶偏导数可以表示为：<br>
$$<br>
\frac{\partial^{2} L}{\partial \theta _{i} \partial \theta _{j}} =<br>
\frac{\partial}{\partial \theta _{j}} \left( \sum _{k=1} ^{m} \frac{\partial L}{\partial \mathbf{z} _{k}^ {(n)}} \frac{\partial \mathbf{z} _{k} ^{(n)}}{\partial \theta _{i}} \right) =<br>
\sum _{k=1} ^{m} \frac{\partial L}{\partial \mathbf{z} _{k} ^{(n)}} \frac{\partial ^{2} \mathbf{z} _{k} ^{(n)}}{\partial \theta _{i} \partial \theta _{j}} +<br>
\sum _{k,l=1} ^{m} \frac{\partial \mathbf{z} _{k} ^{(n)}}{\partial \theta _{i}} \frac{\partial ^{2} L}{\partial \mathbf{z} _{k} ^{(n)} \partial \mathbf{z} _{l} ^{(n)}} \frac{\partial \mathbf{z} _{l} ^{(n)}}{\partial \theta _{j}},<br>
$$</p>
<p>由于预训练模型的参数可以看作已经收敛，因此可以假设原任务损失 $L$ 对 $\mathbf{z}$ 的一阶偏导数近似为 $0$，那么，损失函数对任意一组参数的 Hessian 矩阵可以进一步简化为以下的 Guassian-Newton 矩阵形式：<br>
$$<br>
\mathbf{H} ^{(\theta)} \approx \mathbf{G} ^{(\theta)} = \mathbf{J} _{\mathbf{z} ^{(n)}} \left( \theta \right) ^{\text{T}} \mathbf{H} ^{\mathbf{z} ^ {(n)}} \mathbf{J} _{\mathbf{z} ^{(n)}} \left( \theta \right),<br>
$$</p>
<p>其中 $\mathbf{J} _{\mathbf{z} ^{(n)}} (\theta)$ 是预激活 $\mathbf{z}$ 对网络参数 $\theta$ 的 Jacobi 矩阵，$\mathbf{H} ^{\mathbf{z} ^ {(n)}}$ 是预激活 $\mathbf{z}$ 对任务损失 $L$ 的 Hessian 矩阵。这两个矩阵的规模都很大，因此需要对其进行简化。</p>
<p><strong>简化 Jacobi 矩阵</strong> $\mathbf{J}$。考虑量化对网络层输出的扰动 $\Delta \mathbf{z} ^{(n)}$，Jacobi 矩阵 $\mathbf{J}$ 可以看作对 $\Delta \mathbf{z} ^{(n)}$ 进行一阶泰勒展开后的一阶偏导项：<br>
$$<br>
\Delta \mathbf{z} ^{(n)} = \hat{\mathbf{z}} ^{(n)} - \mathbf{z} ^{(n)} \approx \mathbf{J} _{\mathbf{z} ^{(n)}} (\theta) \Delta \theta.<br>
$$</p>
<p>考虑原量化问题的目标函数，即：<br>
$$<br>
\begin{align*}<br>
\underset{\Delta \theta}{\arg\min} \space \Delta \theta ^{\text{T}} \bar{\mathbf{H}} ^{(\theta)} \Delta \theta<br>
\end{align*}<br>
$$</p>
<p>将 Jacobi 矩阵 $\mathbf{J}$ 用泰勒展开的近似式代入，可得简化的量化目标函数：<br>
$$<br>
\begin{align*}<br>
\underset{\hat{\theta}}{\arg\min} \space \Delta \theta ^{\text{T}} \bar{\mathbf{H}} ^{(\theta)} \Delta \theta \approx \underset{\hat{\theta}}{\arg\min} \space \mathbb{E} \left[ \Delta \mathbf{z} ^{(n),\text{T}} \mathbf{H} ^{\mathbf{z} ^ {(n)}} \Delta \mathbf{z} ^{(n)} \right].<br>
\end{align*}<br>
$$</p>
<p><strong>简化 Hessian 矩阵</strong> $\mathbf{H}$。本文提出使用 Fisher 信息矩阵（Fisher Information Matrix，FIM）来近似预激活 $\mathbf{z}$ 对网络参数 $\theta$ 的 Hessian 矩阵。<br>
给定一个概率模型 $p(x|\theta)$，使用已知的观测样本通过极大似然估计（Maximum Likelyhood Estimate）对参数 $θ$ 进行优化，使得观测样本出现概率取极大值。相当于使评分函数 $s(θ)$，即对数似然函数对参数 $θ$ 的一阶偏导数趋近 $0$。Fisher 信息定义为该一阶偏导数的二阶矩，在一般情况下，对数似然函数对参数 $θ$ 的一阶偏导数的期望为 $0$，因此 Fisher 信息也可以表示为概率模型对参数极大似然估计的评分函数 $s$ 的方差。对于所有参数 $θ$，FIM 表示如下：<br>
$$<br>
\bar{\mathbf{F}} ^{(\theta)} = \mathbb{E} \left[ \nabla _{\theta} \log p _{\theta} (y|x) \nabla _{\theta} \log p _{\theta} (y|x) ^{\text{T}} \right] = - \mathbb{E} \left[ \nabla _{\theta} ^{2} \log p _{\theta} (y|x) \right] = -\bar{\mathbf{H}} _{\log p(x|\theta)} ^{(\theta)}.<br>
$$</p>
<p>可以看出，FIM 也可以等价于概率模型的对数似然函数的 Hessian 矩阵的期望的负值。因此，在二阶优化方法中，FIM 一般可以作为 Hessian 矩阵的近似替代。深度神经网络模型的优化方法与概率模型的极大似然估计方法类似，如果能够尽量保证训练样本的分布尽量接近真实数据分布，并且预训练模型参数已经在训练集上收敛，那么就可以使用 FIM 来近似 Hessian 矩阵 $\mathbf{H}$。<br>
Adam 优化器使用了参数梯度的二阶矩估计来为不同的参数设计独立的自适应学习率，在计算中使用梯度的平方，即 FIM 的对角元素。本文采用类似的思想，使用了 FIM 的对角元素组成的对角矩阵来替换 Hessian 矩阵。一个直观的解释是，梯度平方的值越大，该参数参与量化重建的重要性越高。替换后的优化目标函数变为：<br>
$$<br>
\underset{\hat{\mathbf{w}}}{\min} \space \mathbb{E} \left[ \Delta \mathbf{z} ^{(\ell), \text{T}} \mathbf{H} ^{(\mathbf{z} ^{(\ell)})} \Delta \mathbf{z} ^{(\ell)} \right] =<br>
\underset{\hat{\mathbf{w}}}{\min} \space \mathbb{E} \left[ \Delta \mathbf{z} ^{(\ell), \text{T}} \text{diag}(\mathbf{F} ^{(\mathbf{w})}) \Delta \mathbf{z} ^{(\ell)} \right].<br>
$$</p>
<h3 id="块级重建">块级重建</h3>
<p>前面提到，基于层级的量化重建会损失不同层参数之间的相关性信息，因此需要探究合适的量化粒度来权衡量化优化问题的规模与层级间相关性损失。本文分析了四种不同的量化重建粒度，从大到小依次为整网（Network-wise）重建、阶段（Stage-wise）重建、块级（Block-wise）重建和层级（Layer-wise）重建，不同粒度的规模如 Figure. 7 所示。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/8OMswAEH7UWvGYB.png" alt="Figure. 7 深度神经网络的不同粒度示意图" :="" width="60%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>不同的重建粒度，其 Hessian 矩阵的规模也不同。如 Figure. 8 所示，块级或层级的 Hessian 矩阵相当于整网参数的 Hessian 矩阵的分块对角矩阵。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/opjyAJdLsQCmS7X.png" alt="Figure. 8 不同粒度的 Hessian 矩阵规模示意图" :="" width="50%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>本文对上述四种不同量化粒度的参数重建进行了实验，发现使用块级重建粒度的量化效果最优。使用块级重建的优越性可以从两方面解释。第一，ResNet 等网络采用的残差连接（Residual Connection）可能会加强块级参数的相关性；第二，校准集一般规模较小，要比起粒度更大的阶段或整网重建，块级粒度的参数重建更不容易发生过拟合现象。本文将这种基于块级重建的量化方法称为 BRECQ。</p>
<h2 id="实验-2">实验</h2>
<h3 id="消融实验-2">消融实验</h3>
<p>本文对上面提到的四种不同的重建粒度进行了消融实验。在 ImageNet 图像分类任务上对 ResNet-18 和 MobileNet-V2 模型进行 2-bit 量化，结果见 Table. 2。结果表明，块级重建的量化效果要比其它粒度的效果要好。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/FSJeOwvZKW3kUgr.png" alt="Table. 6 不同重建粒度的消融实验" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<h3 id="对比实验-2">对比实验</h3>
<p>本文在 ImageNet 图像分类任务和 MS COCO 目标检测任务上展开工作。<br>
在 ImageNet 图像分类任务上的对比结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/5ywcma3zeUfQjit.png" alt="Table. 7 BRECQ 在 ImageNet 图像分类任务上的各模型的对比实验结果" :="" width="90%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>在 MS COCO 目标检测任务上的对比结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/5ywcma3zeUfQjit.png" alt="Table. 8 BRECQ 在 MS COCO 目标检测任务上的各模型的对比实验结果" :="" width="90%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="总结-2">总结</h2>
<p>本文提出了 BRECQ，一种由 AdaRound 改进而来的基于块级重建的后训练量化方法。BRECQ 设计了新的优化目标函数，充分考虑了块内参数之间的相关性，弥补了层级重建中层级间的参数相关性的损失。BRECQ 的量化效果要显著优于比 AdaRound 以及其它的基于重建的量化方法。<br>
商汤科技模型部署与工具链团队在将 BRECQ 方法作为后训练量化算法的示例整合到了他们推出的开源模型量化框架 MQBench<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup> 中。</p>
<h1>QDrop</h1>
<blockquote>
<ul>
<li>Title: <strong>QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization</strong></li>
<li>Venue: <em><strong>ICLR 2022</strong></em></li>
<li>Author(s): Xiuying Wei, Ruihao Gong, Yuhang Li, Xianglong Liu, Fengwei Yu</li>
<li>Institution(s): State Key Lab of Software Development Environment, Beihang University, SenseTime Research</li>
<li>Link: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.05740">arxiv:2203.05740</a></li>
</ul>
</blockquote>
<h2 id="前言-3">前言</h2>
<p>常规的 PTQ 方法对网络权重和激活的量化是相互独立的，一般的流程是先量化权重值，再量化激活值。AdaRound 和 BRECQ 方法与传统 PTQ 方法类似，它们都是先对网络权重参数进行重建，然后使用传统方法对激活值进行量化。这种 PTQ 流程忽略了激活量化对权重量化的影响，依然存在改进空间。本文提出的 QDrop 在 BRECQ 的基础上进行了改进，将对网络权重的重建和对激活量化的优化结合在一起，充分考虑到了整体的量化损失。QDrop 的量化效果在量化不友好的网络（例如 MobileNet-V2）上显著超越了之前的方法。</p>
<h2 id="方法-3">方法</h2>
<h3 id="激活量化如何影响权重量化">激活量化如何影响权重量化</h3>
<p>为了验证激活量化对权重参数重建的影响，本文首先基于 BRECQ 方法针对三种不同的激活量化策略开展了对比实验进行观察，三种激活量化策略如下，示意图和结果如 Figure. 9 所示。</p>
<ul>
<li><strong>Case 1</strong>：原始的 BRECQ 方法。重建时不对激活进行量化；</li>
<li><strong>Case 2</strong>：对当前重建的块以及之前的所有重建完毕的块的激活进行量化。</li>
<li><strong>Case 3</strong>：对当前重建的块之前的所有重建完毕的块的激活进行量化，不对当前块的激活进行量化。</li>
</ul>
<p><img data-src="https://s2.loli.net/2025/06/30/OrTRxlvtLEID4Ws.png" alt="Figure. 9 三种激活量化策略示意图及量化结果" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>实验表明，Case 3 的量化效果最好。也就是说，如果在参数重建的过程中对部分块进行激活量化，有可能提高量化效果。<br>
类似于之前对权重量化的数学定义，对激活的量化也可以定义为对其的扰动，记为 $e=(\hat{a} - a)$，</p>
<p>本文将该扰动由减法形式转化为乘法形式，即 $\hat{a} = a \cdot (1+u)$。定义同时对权重和激活的量化扰动的全局损失为 $L(\boldsymbol{w} + \Delta \boldsymbol{w}, \boldsymbol{x}, \mathbf{1} + \boldsymbol{u}(\boldsymbol{x}))$，那么量化要优化的目标函数为：<br>
$$<br>
\min _{\hat{\boldsymbol{w}}} \mathbb{E} _{\boldsymbol{x}\sim\mathcal{D} _{c}} [L(\boldsymbol{w} + \Delta \boldsymbol{w}, \boldsymbol{x}, \boldsymbol{1} + \boldsymbol{u}(\boldsymbol{x})) - L(\boldsymbol{w}, \boldsymbol{x}, \boldsymbol{1})].<br>
$$</p>
<p>卷积、全连接等线性变换层的运算均可以用矩阵乘法 $\boldsymbol{y}=\boldsymbol{W}\boldsymbol{a}$ 来表示。对激活 $\boldsymbol{a}$ 加入的扰动 $\boldsymbol{u}(\boldsymbol{x})$ ，可以传递到对权重 $\boldsymbol{W}$ 上：<br>
$$<br>
\boldsymbol{W}(\boldsymbol{a} \odot<br>
\begin{bmatrix}<br>
1 + \boldsymbol{u} _{1}(\boldsymbol{x}) \\<br>
1 + \boldsymbol{u} _{2}(\boldsymbol{x}) \\<br>
… \\<br>
1 + \boldsymbol{u} _{n}(\boldsymbol{x})<br>
\end{bmatrix})<br>
= (\boldsymbol{W} \odot<br>
\begin{bmatrix}<br>
1 + \boldsymbol{u} _{1}(\boldsymbol{x}) &amp; 1 + \boldsymbol{u} _{2} (\boldsymbol{x}) &amp; … &amp; 1 + \boldsymbol{u} _{n}(\boldsymbol{x}) \\<br>
1 + \boldsymbol{u} _{1}(\boldsymbol{x}) &amp; 1 + \boldsymbol{u} _{2} (\boldsymbol{x}) &amp; … &amp; 1 + \boldsymbol{u} _{n}(\boldsymbol{x}) \\<br>
… \\<br>
1 + \boldsymbol{u} _{1}(\boldsymbol{x}) &amp; 1 + \boldsymbol{u} _{2} (\boldsymbol{x}) &amp; … &amp; 1 + \boldsymbol{u} _{n}(\boldsymbol{x})<br>
\end{bmatrix})<br>
\boldsymbol{a}.<br>
$$</p>
<p>目标函数可以进一步转化为：<br>
$$<br>
\mathbb{E} _{\boldsymbol{x}\sim\mathcal{D} _{c}} [L (\hat{\boldsymbol{w}}, \boldsymbol{x}, \mathbf{1} + \boldsymbol{u}(\boldsymbol{x})) - L(\boldsymbol{w}, \boldsymbol{x}, \boldsymbol{1})] \approx \mathbb{E} _{\boldsymbol{x}\sim\mathcal{D} _{c}} [L(\hat{\boldsymbol{w}} \odot(\mathbf{1} + \boldsymbol{v}(\boldsymbol{x})), \boldsymbol{x}, \boldsymbol{1}) - L(\boldsymbol{w}, \boldsymbol{x}, \boldsymbol{1})],<br>
$$</p>
<p>$$<br>
\begin{align*}<br>
\mathbb{E} _{\boldsymbol{x} \sim \mathcal{D} _{c}} [L(\hat{\boldsymbol{w}}, \boldsymbol{x}, \boldsymbol{1} + \boldsymbol{u}(\boldsymbol{x})) - L(\boldsymbol{w}, \boldsymbol{x}, \boldsymbol{1})] &amp;\approx \\<br>
\mathbb{E} _{\boldsymbol{x} \sim \mathcal{D} _{c}} [\underbrace{(L(\hat{\boldsymbol{w}}, \boldsymbol{x}, \boldsymbol{1}) - L(\boldsymbol{w},\boldsymbol{x}, \boldsymbol{1}))} _{(7-1)} &amp;+ \underbrace{(L(\hat{\boldsymbol{w}} \odot (\boldsymbol{1} + \boldsymbol{v}(\boldsymbol{x})), \boldsymbol{x}, \boldsymbol{1}) - L(\hat{\boldsymbol{w}}, \boldsymbol{x}, \boldsymbol{1}))} _{(7-2)}]<br>
\end{align*}<br>
$$<br>
上式的第一项为权重参数重建的损失，第二项为参数重建后的网络再加入激活量化之后的损失。也就是说，通过乘法项引入的对激活的量化扰动，对整体的量化损失是有影响的。<br>
可以从量化扰动鲁棒性的角度来理解由激活引入的第二项损失。对激活的量化可以看作对参数重建后的量化网络加入的噪声。如果在输入加入了噪声的情况下进行优化，网络参数优化时的损失平面理论上会更加平坦，即鲁棒性更强。这也解释了前面对比实验中 Case 2 和 Case 3 比第一种情况的效果更好的原因。</p>
<h3 id="QDrop">QDrop</h3>
<p>本文提出了一种权重和激活量化相结合的参数重建优化方案，命名为 QDrop。QDrop 是从前文所述的对比实验的第三种情况加以改进得到的。与原先不同的是，QDrop 对当前重建的层也加入了对输入激活的量化，但是只会以一定的概率 $p$ 来决定输入的每一个元素是否不进行量化，类似于深度学习中的 Dropout，即：<br>
$$<br>
\mathrm{QDROP}:u=<br>
\begin{cases}<br>
0 &amp; \text{with probability }p \\<br>
\frac{\hat{a}}{a}-1 &amp; \text{with probability }1-p &amp;<br>
\end{cases}.<br>
$$</p>
<p>使用 QDrop 得到的参数优化损失平面与其它情况的对比如 Figure. 10 所示。可以看到，使用 QDrop 方法的损失平面要比之前更加平坦。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/UvwfYtqh6uKpnHz.png" alt="Figure. 10 Case 1、Case 3 和 QDrop 的参数损失平面对比" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="实验-3">实验</h2>
<h3 id="消融实验-3">消融实验</h3>
<p><strong>QDrop 与 No Drop</strong>。本文对比了使用 QDrop 方法进行随机地激活量化和完全进行激活量化的效果。结果如表所示。结果表明使用 QDrop 后预测精度有所提升。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/GuDA6avXFVfoUjW.png" alt="Table. 9 QDrop 与 No Drop 消融实验结果" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<p><strong>QDrop 概率 $p$ 的选择</strong>。本文对 QDrop 概率 $p$ 的选择进行了消融实验，结果如图所示。结果表明，QDrop 概率 $p$ 的值对量化效果有较大影响，过小或过大的概率都会导致量化效果下降。<br>
可以看出，当 $p=0.5$ 时量化模型的预测精度最高。但对于更细粒度的搜索空间本文未作过多讨论。</p>
<p><img data-src="https://s2.loli.net/2025/06/30/hdjKBA2LsMN8IQp.png" alt="Figure. 11 不同概率 $p$ 下 QDrop 实验结果" :="" width="40%" loading="lazy" style="margin-bottom: 30px;"></p>
<h3 id="对比实验-3">对比实验</h3>
<p>QDrop 在 ImageNet 图像分类任务、MS COCO 目标检测任务和各个自然语言处理任务上展开工作。<br>
在 ImageNet 图像分类任务上的对比结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/dB3s2aZhxkcbUm7.png" alt="Table. 10 QDrop 在 ImageNet 图像分类任务上的各模型的对比实验结果" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>在 MS COCO 目标检测任务上的对比结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/JSqr9tYu4aCgT2G.png" alt="Table. 11 QDrop 在 MS COCO 目标检测任务上的各模型的对比实验结果" :="" width="80%" loading="lazy" style="margin-bottom: 30px;"></p>
<p>在各个自然语言处理任务上的对比结果如下：</p>
<p><img data-src="https://s2.loli.net/2025/06/30/ahRES1oBC6mVUQM.png" alt="Table. 12 QDrop 在各个 NLP 任务上的各模型的对比实验结果" :="" width="90%" loading="lazy" style="margin-bottom: 30px;"></p>
<h2 id="总结-3">总结</h2>
<p>本文提出了 QDrop，一种由 BRECQ 改进而来的基于块级重建的后训练量化方法。基于重建的优化方法相比过去的 PTQ 方法的一个优势在于，激活量化和权重量化可以同时进行。QDrop 将对激活的量化与对权重的重建结合到了一起，充分考虑了量化任务对网络模型的整体影响，最终的量化效果达到了 PTQ 方法的新极限。<br>
商汤科技模型部署与工具链团队在 ICLR 2022 发表相关研究论文之后，将 QDrop 方法作为后训练量化算法的示例整合到了他们推出的开源模型量化框架 MQBench 中，并将在之后陆续支持对 NLP 相关任务的网络模型的量化。</p>
<h1>参考文献</h1>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.07145">Zhewei Yao, Amir Gholami, Kurt Keutzer, et al. PyHessian: Neural Networks Through the Lens of the Hessian. BigData 2020.</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.10518">Markus Nagel, Rana Ali Amjad, Mart van Baalen, et al. Up or Down? Adaptive Rounding for Post-Training Quantization. ICML, 2020.</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.05426v2">Yuhang Li, Ruihao Gong, Xu Tan, et al. BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction. ICLR, 2021.</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.05740">Xiuying Wei, Ruihao Gong, Yuhang Li, et al. QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization. ICLR, 2022.</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Two-Step_Quantization_for_CVPR_2018_paper.pdf">Peisong Wang, Qinghao Hu, Yifan Zhang, et al. Two-Step Quantization for Low-bit Neural Networks. CVPR 2018.</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.10518">Itay Hubara, Yury Nahshan, Yair Hanani, et al. Improving Post Training Neural Quantization: Layer-wise Calibration and Integer Programming. ICML, 2021.</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v119/wang20c/wang20c.pdf">Peisong Wang, Qiang Chen, Xiangyu He, et al. Towards Accurate Post-training Network Quantization via Bit-Splitting and Stitching. ICML, 2020.</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.08442">Sangeetha Siddegowda, Marios Fournarakis, Markus Nagel, et al. Neural Network Quantization with AI Model Efficiency Toolkit (AIMET). ArXiv, 2022, abs/2201.08442.</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2111.03759">Yuhang Li, Mingzhu Shen, Yan Ren, et al. MQBench: Towards Reproducible and Deployable Model Quantization Benchmark. NeurIPS Track on Datasets and Benchmarks, 2021.</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>scxs1388
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://scxs1388.github.io/2022/03/15/hessian_ptq/" title="Hessian-based Post-Training Quantization">http://scxs1388.github.io/2022/03/15/hessian_ptq/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep Learning</a>
              <a href="/tags/Post-Training-Quantization/" rel="tag"><i class="fa fa-tag"></i> Post-Training Quantization</a>
              <a href="/tags/Hessian-Matrix/" rel="tag"><i class="fa fa-tag"></i> Hessian Matrix</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/12/04/break-md5/" rel="prev" title="How to Break MD5 and Other Hash Functions">
      <i class="fa fa-chevron-left"></i> How to Break MD5 and Other Hash Functions
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF"><span class="nav-number">1.1.</span> <span class="nav-text">问题背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.2.</span> <span class="nav-text">神经网络量化的基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8F%E5%8C%96"><span class="nav-number">1.2.1.</span> <span class="nav-text">量化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8F%E5%8C%96%E7%9A%84%E6%95%B0%E5%AD%A6%E8%A1%A8%E7%A4%BA"><span class="nav-number">1.2.2.</span> <span class="nav-text">量化的数学表示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8E%E8%AE%AD%E7%BB%83%E9%87%8F%E5%8C%96%E5%92%8C%E9%87%8F%E5%8C%96%E6%84%9F%E7%9F%A5%E8%AE%AD%E7%BB%83"><span class="nav-number">1.2.3.</span> <span class="nav-text">后训练量化和量化感知训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hessian-%E7%9F%A9%E9%98%B5"><span class="nav-number">1.3.</span> <span class="nav-text">Hessian 矩阵</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">AdaRound</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">2.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E5%85%A8%E5%B1%80%E6%8D%9F%E5%A4%B1%E5%88%B0%E5%B1%80%E9%83%A8%E6%8D%9F%E5%A4%B1"><span class="nav-number">2.2.1.</span> <span class="nav-text">从全局损失到局部损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AdaRound"><span class="nav-number">2.2.2.</span> <span class="nav-text">AdaRound</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">2.3.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="nav-number">2.3.1.</span> <span class="nav-text">消融实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C"><span class="nav-number">2.3.2.</span> <span class="nav-text">对比实验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">BRECQ</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80-2"><span class="nav-number">3.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-2"><span class="nav-number">3.2.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E5%B1%82%E9%97%B4%E5%8F%82%E6%95%B0%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="nav-number">3.2.1.</span> <span class="nav-text">不同层间参数的相关性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9D%97%E7%BA%A7%E9%87%8D%E5%BB%BA"><span class="nav-number">3.2.2.</span> <span class="nav-text">块级重建</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C-2"><span class="nav-number">3.3.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C-2"><span class="nav-number">3.3.1.</span> <span class="nav-text">消融实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C-2"><span class="nav-number">3.3.2.</span> <span class="nav-text">对比实验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-2"><span class="nav-number">3.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">QDrop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80-3"><span class="nav-number">4.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-3"><span class="nav-number">4.2.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E9%87%8F%E5%8C%96%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E6%9D%83%E9%87%8D%E9%87%8F%E5%8C%96"><span class="nav-number">4.2.1.</span> <span class="nav-text">激活量化如何影响权重量化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#QDrop"><span class="nav-number">4.2.2.</span> <span class="nav-text">QDrop</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C-3"><span class="nav-number">4.3.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C-3"><span class="nav-number">4.3.1.</span> <span class="nav-text">消融实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C-3"><span class="nav-number">4.3.2.</span> <span class="nav-text">对比实验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-3"><span class="nav-number">4.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="scxs1388"
      src="/images/37069157.jpg">
  <p class="site-author-name" itemprop="name">scxs1388</p>
  <div class="site-description" itemprop="description">Suffering from acute coke overdose</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/scxs1388" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;scxs1388" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:scxs138@gmail.com" title="E-Mail → mailto:scxs138@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">scxs1388</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">24k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:01</span>

</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
    <!-- 从这里开始添加代码 -->
    <span class="post-meta-divider">|</span>
    <span id="sitetime" class="post-meta-item"></span>
    <script>
        function siteTime(){
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth()+1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        var t1 = Date.UTC(2021,09,01,00,00,00); // 网站建立时间
        var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff/years);
        var diffDays = Math.floor((diff/days)-diffYears*365);
        var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
        var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
        var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
        document.getElementById("sitetime").innerHTML=" 本站已安全运行 "+diffYears+" years "+diffDays+" days "+diffHours+" hours "+diffMinutes+" mins "+diffSeconds+" secs";
        }
        siteTime();
    </script>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : true,
      notify     : false,
      appId      : 'mojaLGNNMrKkKETfoAux4Kqt-gzGzoHsz',
      appKey     : 'DLhcFTxQjAu7AqlSKauBv6cH',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
